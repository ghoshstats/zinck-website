---
title: "Colorectal Cancer (CRC) Study"
author: "Soham Ghosh"
date: "2024-06-18"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---

## CRC Data Analysis 

We applied Zinck to meta-analyze five metagenomics studies of CRC. The five studies correspond to five different countries for the CRC data, which are named ``AT" (Australia), ``US" (USA), ``CN" (China), ``DE" (Germany), and ``FR" (France).  The sample sizes are 109, 127, 120, 114, and 104, respectively, and the number of cases and controls is roughly balanced in each study. We focus on the most abundant $300$ species.

```{r CRC-data}
##################### CRC data species level ##########################
#######################################################################
library(randomForest)
library(zinck)
library(reshape2)
library(knockoff)
library(ggplot2)
library(rstan)

load("/Users/Patron/Documents/zinLDA research/count.Rdata")
load("/Users/Patron/Documents/zinLDA research/meta.RData")
dcount <- count[,order(decreasing=T,colSums(count,na.rm=T),
                       apply(count,2L,paste,collapse=''))][,1:300]
## ordering the columns w/ decreasing abundance
X <- dcount
Y <- as.factor(meta$Group)
lookup <- c("CTR" = 0, "CRC" = 1)
Y <- lookup[Y]    ## Converting into 0/1 data
```

We train the zinck model on $X$ using ADVI with an optimal number of clusters (19). We generate the knockoff matrix $\tilde{X}$ by plugging in the learnt  parameters into the generative model.

```{r zinck-fit}
dlt <- rep(0,ncol(X)) ## Initializing deltas with the individual column sparsities

for(t in (1:ncol(X)))
{
  dlt[t] <- 1-mean(X[,t]>0)
  if(dlt[t]==0)
  {
    dlt[t] = dlt[t]+0.01
  }
  if (dlt[t]==1)
  {
    dlt[t] = dlt[t]-0.01
  }
  
}

zinLDA_stan_data <- list(
  K = 19,
  V = ncol(X),
  D = nrow(X),
  n = X,
  delta = dlt
)

zinck_code <- "data {
  int<lower=1> K; // num topics
  int<lower=1> V; // num words
  int<lower=0> D; // num docs
  int<lower=0> n[D, V]; // word counts for each doc

  // hyperparameters
  vector<lower=0, upper=1>[V] delta;
}

parameters {
  simplex[K] theta[D]; // topic mixtures
  vector<lower=0, upper=1>[V] zeta[K]; // zero-inflated betas
  vector<lower=0>[V] gamma1[K];
  vector<lower=0>[V] gamma2[K];
  vector<lower=0>[K] alpha;
}

transformed parameters {
  vector[V] beta[K];

  // Efficiently compute beta using vectorized operations
  for (k in 1:K) {
    vector[V] cum_log1m;
    cum_log1m[1:(V - 1)] = cumulative_sum(log1m(zeta[k, 1:(V - 1)]));
    cum_log1m[V] = 0;
    beta[k] = zeta[k] .* exp(cum_log1m);
    beta[k] = beta[k] / sum(beta[k]);
  }
}


model {
  for (k in 1:K) {
    alpha[k] ~ gamma(100,100);  // Change these hyperparameters as needed
  }
  for (d in 1:D) {
    theta[d] ~ dirichlet(alpha);
  }
  for (k in 1:K) {
    for (m in 1:V) {
        gamma1[k,m] ~ gamma(1,1);
        gamma2[k,m] ~ gamma(1,1);
    }
  }

  // Zero-inflated beta likelihood and data likelihood
  for (k in 1:K) {
    for (m in 1:V) {
      real lp_non_zero = bernoulli_lpmf(0 | delta[m]) + beta_lpdf(zeta[k, m] | gamma1[k, m], gamma2[k, m]);
      real lp_zero = bernoulli_lpmf(1 | delta[m]);
      target += log_sum_exp(lp_non_zero, lp_zero);
    }
  }

  // Compute the eta values and data likelihood more efficiently
  for (d in 1:D) {
    vector[V] eta = theta[d, 1] * beta[1];
    for (k in 2:K) {
      eta += theta[d, k] * beta[k];
    }
    eta = eta / sum(eta);
    n[d] ~ multinomial(eta);
  }
}
"

stan.model = stan_model(model_code = zinck_code)

set.seed(1)
fitCRC <- vb(stan.model, data=zinLDA_stan_data, algorithm="meanfield", iter=10000) ## Fitting the zinck model

theta <- fitCRC@sim[["est"]][["theta"]]
beta <- fitCRC@sim[["est"]][["beta"]]
X_tilde_CRC <- zinck::generateKnockoff(X,theta,beta,seed=1) ## Generating the knockoff copy

```

We move on to fit a tuned Random Forest model relating the augmented set of covariates with the outcome of interest $Y$.

```{r rf-model}

X_aug <- cbind(X,X_tilde_CRC) ## Creating the augmented matrix

######### Tuning the Random Forest model ####################
bestmtry <- tuneRF(X_aug,as.factor(Y),stepFactor = 1.5,improve=1e-5,ntree=1000) ## Getting the best mtry hyperparameter
m <- bestmtry[as.numeric(which.min(bestmtry[,"OOBError"])),1]
df_X <- as.data.frame(X_aug)
colnames(df_X) <- NULL
rownames(df_X) <- NULL
df_X$Y <- Y
model_rf <- randomForest(formula=as.factor(Y)~.,ntree=1000,mtry=m,
                         importance=TRUE,data=as.matrix(df_X)) ## Fitting the tuned Random Forest model
cf <- as.data.frame(importance(model_rf))[,3] ## Extracting the Mean Decrease in Impurities for each variable
W <- abs(cf[1:300])-abs(cf[301:600])
T <- knockoff.threshold(W,fdr = 0.1, offset = 0) ## This is the knockoff threshold
print(which(W>=T))
names_zinck <- colnames(X[,which(W>=T)])
```

Finally, we can visualize the importance of these selected species using the Feature Statistics obtained by contrasting the Random Forest importance scores of the original and the knockoff features.

```{r imp-plots}

data.species <- data.frame(impscores=sort(W[which(W>=T)],decreasing = FALSE), 
                         name=factor(names_zinck, levels=names_zinck), y=seq(length(names_zinck))*0.9)

plot.species <- ggplot(data.species)+geom_col(aes(impscores,name),
                                          fill="black",width=0.6)+theme_bw()+
  ylab("Species")+xlab("Feature Statistic")

plot.species


```

