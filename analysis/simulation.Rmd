---
title: "Simulations"
author: "Soham Ghosh"
date: "2024-12-11"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---
## Empirical Power and False Discovery Rate for different target thresholds

```{r defn, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
library(zinck)
library(reshape2)
library(knockoff)
library(ggplot2)
library(rstan)
library(phyloseq)
library(kosel)
library(dplyr)
library(glmnet)
library(topicmodels)
library(knitr)
library(kableExtra)

load("/Users/Patron/Documents/zinck research/count.Rdata")
load("/Users/Patron/Documents/zinck research/meta.RData")
# zinck_code <- "data {
#   int<lower=1> K; // num topics
#   int<lower=1> V; // num words
#   int<lower=0> D; // num docs
#   int<lower=0> n[D, V]; // word counts for each doc
# 
#   // hyperparameters
#   vector<lower=0>[K] alpha;
#   vector<lower=0>[V] gamma1;
#   vector<lower=0>[V] gamma2;
#   vector<lower=0, upper=1>[V] delta;
# }
# parameters {
#   simplex[K] theta[D]; // topic mixtures
#   vector<lower=0,upper=1>[V] zeta[K]; // zero-inflated betas
# }
# 
# 
# transformed parameters {
#   vector<lower=0>[V] beta[K];
#   for (k in 1:K) {
# 	beta[k,1] =  zeta[k,1];
#   for (m in 2:V) {
#     beta[k,m] = zeta[k,m]*prod(1 - zeta[k,1:(m - 1)]);  // stick breaking
#   }
#   }
#   for (k in 1:K) {
#       beta[k]=beta[k]/sum(beta[k,1:V]);  // GD construction
#   }
# }
# 
# 
# model {
#   for (d in 1:D) {
#     theta[d] ~ dirichlet(alpha);
#   }
# 
#   for (k in 1:K) {
#     for (m in 1:V) {
#       if (zeta[k,m]==0){  // Zero-inflated beta likelihood
#         target += bernoulli_lpmf(1 | delta[m]);
#       }else{
#         target += bernoulli_lpmf(0 | delta[m]) + beta_lpdf(zeta[k,m] | gamma1[m], gamma2[m]);
#       }
# 		}
#   }
# 
#   for (d in 1:D) {
#     vector[V] eta;
#     eta = beta[1] * theta[d, 1];
#     for (k in 2:K) {
#       eta = eta + beta[k] * theta[d, k];
#     }
#     eta = eta/sum(eta[1:V]);
#     n[d] ~ multinomial(eta);  // generation of each sample
#   }
# }
# "

```


We take the colon cancer (CRC) dataset which encompasses five distinct studies each originating from different countries. We calculated the average proportions of species across all $574$ samples from five metagenomic studies and retained the top $p = 200$ most abundant species. Then, we randomly sampled $D = 500$ samples from the cohort of $574$ observations and normalized their raw OTU counts row-wise, ensuring each row sums to $1$. To avoid zero probabilities during multinomial sampling, a small constant ($0.5$) was added to the raw OTU counts before normalization.

Next, we paired the calculated true proportions $\Pi$ with sequencing depths resampled from the original dataset. Each sequencing depth was independently resampled and paired with a proportion vector from a different subject. Using these paired proportions and sequencing depths, we generated the taxa count matrix $\mathbf{X}^{D \times p}$ via multinomial sampling. For each sample $d = 1, 2, \ldots, 500$, the count vector corresponding to the $d^{\text{th}}$ row of $\mathbf{X}$ was generated as:
$$
\mathbf{X}_d \sim \text{Multinomial}(N_d, \Pi_d),
$$
where $N_d$ is the sequencing depth for sample $d$, and $\Pi_d$ is the vector of true proportions for sample $d$ with $\Pi_{dj}$ (j = 1...p) as its element.

Given the simulated count, among the first $200$ taxa, $30$ were randomly assumed to be associated with the outcome, while the remaining $p-30$ taxa had no effect. To simulate outcomes reflecting realistic microbiome data, signal strengths $\boldsymbol{s}$ for the associated $30$ biomarkers were defined as:
$$
s_j \overset{d}{=}  
\begin{cases} 
    (2Z_j - 1) \frac{U_1}{\sqrt{C_j}}, & \text{for continuous outcomes}, \\
    (2Z_j - 1) \frac{U_2}{\sqrt{C_j}}, & \text{for binary outcomes},
\end{cases}
$$
where $U_1 \sim \text{Uniform}(6, 12)$ and $U_2 \sim \text{Uniform}(30, 50)$ represent the signal magnitudes, $Z_j \sim \text{Bernoulli}(0.5)$ determines the sign of $s_j$ ($+1$ or $-1$), and $C_j$ is the column-wise average abundance of the $j^{\text{th}}$ bio-marker in $\Pi$.

Outcomes were generated using the following model:
$$
   g(\mathbb{E}(y_d)) = \sum_{j=1}^{p} \left \{ \Pi_{dj}^2 \times \left(\frac{s_j}{2}\right) + \Pi_{dj} \times s_j \right \} 
$$

where $g(\cdot)$ is the identity link for continuous outcomes and the logit link for binary outcomes. 
We replicate a single iteration of this setting for both continuous and binary outcomes.

```{r simulation-setting}
generate_data <- function(p, seed) {
  dcount <- count[, order(decreasing = TRUE, colSums(count, na.rm = TRUE), apply(count, 2L, paste, collapse = ''))] # Ordering the columns with decreasing abundance
  
  # Randomly sampling patients from 574 observations
  set.seed(seed)
  norm_count <- count / rowSums(count)
  col_means <- colMeans(norm_count > 0)
  indices <- which(col_means > 0.2)
  sorted_indices <- indices[order(col_means[indices], decreasing = TRUE)]
  
  if (p %in% c(200, 300, 400)) {
    dcount <- count[, sorted_indices][, 1:p]
    sel_index <- sort(sample(1:nrow(dcount), 500))
    dcount <- dcount[sel_index, ]
    original_OTU <- dcount + 0.5
    seq_depths <- rowSums(original_OTU)
    Pi <- sweep(original_OTU, 1, seq_depths, "/")
    n <- nrow(Pi)
    
    col_abundances <- colMeans(Pi)
    
    ##### Generating continuous responses ######
    set.seed(1)
    signal_indices <- sample(1:min(p, 200), 30, replace = FALSE) # Randomly selecting 30 indices for signal injection
    signals <- (2 * rbinom(30, 1, 0.5) - 1) * runif(30, 6, 12)
    kBeta <- numeric(p)
    kBeta[signal_indices] <- signals / sqrt(col_abundances[signal_indices])
    
    eps <- rnorm(n, mean = 0, sd = 1)
    Y <- Pi^2 %*% (kBeta / 2) + Pi %*% kBeta + eps
    
    ##### Generating binary responses #####
    set.seed(1)
    signals <- (2 * rbinom(30, 1, 0.5) - 1) * runif(30, 30, 50)
    kBeta[signal_indices] <- signals / sqrt(col_abundances[signal_indices])
    
    pr <- 1 / (1 + exp(-(Pi^2 %*% (kBeta / 2) + Pi %*% kBeta)))
    Y_bin <- rbinom(n, 1, pr)
    
    ######### Generate a copy of X #########
    X <- matrix(0, nrow = nrow(Pi), ncol = ncol(Pi))
    nSeq <- seq_depths
    
    # Loop over each row to generate the new counts based on the multinomial distribution
    set.seed(1)
    for (i in 1:nrow(Pi)) {
      X[i, ] <- rmultinom(1, size = nSeq[i], prob = Pi[i, ])
    }
    
  } else {
    print("Enter p within 200 to 400")
  }
  
  colnames(X) <- colnames(Pi)
  return(list(Y = Y, X = X, Y_bin = Y_bin, signal_indices = signal_indices))
}


ntaxa = 200 # Change to p = 200, 300, 400 accordingly.

X <- generate_data(p=ntaxa, seed=1)$X
Y1 <- generate_data(p=ntaxa, seed=1)$Y


```

On extracting the sample taxa count matrix $X$ and continuous outcomes $Y_1$, we train the zinck model using ADVI. Plugging in the learnt parameters into the generative framework of `zinck`, we generate the knockoff matrix $\tilde{X}$. 

```{r zinck-fit, message=FALSE, warning=FALSE, results='hide'}

# K =16, seed=19
fit <- fit.zinck(X,num_clusters = 18,method="ADVI",seed=1,boundary_correction = TRUE, prior_ZIGD = TRUE)
theta <- fit$theta
beta <- fit$beta
X_tilde <- zinck::generateKnockoff(X,theta,beta,seed=1) ## getting the knockoff copy


```

Now that we have generated the knockoff copy, we will fit a model associating the response $Y_1$  with the augmented set of covariates $[X,\tilde{X}]^{D \times 2p}$. We fit a Random Forest model and compute the importance statistics for each feature. Then, we detect the non-zero features for the FDR threshold of $0.2$. Then, we compute the Power (True Positive Rate) and the empirical FDR by comparing the selected set of taxa with the true set of taxa.

```{r model-continuous}
index <- generate_data(p=ntaxa,seed=1)$signal_indices
################### Continuous Outcomes #########################
############## Target FDR = 0.2 ###############
cts_rf <- suppressWarnings(zinck.filter(X,X_tilde,Y1,model="Random Forest",fdr=0.2,ntrees=5000,offset=1,mtry=400,seed=15,metric = "Accuracy", rftuning = TRUE))
index_est <- cts_rf[["selected"]]

### Evaluation metrics ###
FN <- sum(index %in% index_est == FALSE) ## False Negatives
FP <- sum(index_est %in% index == FALSE) ## False Positives
TP <- sum(index_est %in% index == TRUE) ## True Positives

estimated_FDR_zinck_cts <- FP / (FP + TP) # Evaluating the empirical False Discovery Rate
estimated_power_zinck_cts <- TP / (TP + FN) # Evaluating the empirical Power or TPR

print(paste("Estimated FDR for Target 0.2 (Continuous case):", estimated_FDR_zinck_cts))
print(paste("Estimated Power for Target 0.2 (Continuous case):", estimated_power_zinck_cts))

```

It is to be noted that `zinck` is outcome agnostic! That is, it performs feature selection irrespective of the outcome type. Thus, we demonstrate its power and empirical FDR for binary outcomes $Y_2$.

```{r model-binary}
Y2 <- generate_data(p=ntaxa, seed=1)$Y_bin
index <- generate_data(p=ntaxa,seed=1)$signal_indices
################### Binary Outcomes #########################
############## Target FDR = 0.2 ###############
bin_rf <- suppressWarnings(zinck.filter(X,X_tilde,as.factor(Y2),model="Random Forest",fdr=0.2,offset=0,mtry=45,seed=68,metric="Gini",rftuning = TRUE))
index_est <- bin_rf[["selected"]]

### Evaluation metrics ###
FN <- sum(index %in% index_est == FALSE) ## False Negatives
FP <- sum(index_est %in% index == FALSE) ## False Positives
TP <- sum(index_est %in% index == TRUE) ## True Positives

estimated_FDR_zinck_bin <- FP / (FP + TP) # Evaluating the empirical False Discovery Rate
estimated_power_zinck_bin <- TP / (TP + FN) # Evaluating the empirical Power or TPR

print(paste("Estimated FDR for Target 0.2 (Binary case):", estimated_FDR_zinck_bin))
print(paste("Estimated Power for Target 0.2 (Binary case):", estimated_power_zinck_bin))


```

We now compare the performance of `zinck` with two standard knockoff filters namely, Model-X Knockoff Filter (MX-KF) and the standard LDA based knockoff filter (LDA-KF) keeping the same FDR threshold of $0.2$. It is to be noted that for fitting MX-KF, we need to generate the second-order knockoff copies for the log-normalized version of $\mathbf{X}$.

```{r otherfilters}
################ Continuous Outcomes (MX-KF) ##################
set.seed(1)
Xlog = log_normalize(X)
Xlog_tilde = create.second_order(Xlog)
index_est <- zinck.filter(Xlog,Xlog_tilde,Y1,model="Random Forest",fdr=0.2,seed=4)$selected

### Evaluation metrics ###
FN <- sum(index %in% index_est == FALSE) ## False Negatives
FP <- sum(index_est %in% index == FALSE) ## False Positives
TP <- sum(index_est %in% index == TRUE) ## True Positives

estimated_FDR_KF_cts <- FP / (FP + TP) # Evaluating the empirical False Discovery Rate
estimated_power_KF_cts <- TP / (TP + FN) # Evaluating the empirical Power or TPR

cat("MX-KF (Continuous) metrics\n")
cat("Estimated FDR for Target 0.2:", estimated_FDR_KF_cts, "\n")
cat("Estimated Power for Target 0.2:", estimated_power_KF_cts, "\n")

############### Binary Outcomes (MX-KF) ###################
index_est <- zinck.filter(Xlog,Xlog_tilde,as.factor(Y2),model="Random Forest",fdr=0.2,seed=1)$selected

### Evaluation metrics ###
FN <- sum(index %in% index_est == FALSE) ## False Negatives
FP <- sum(index_est %in% index == FALSE) ## False Positives
TP <- sum(index_est %in% index == TRUE) ## True Positives

estimated_FDR_KF_bin <- FP / (FP + TP) # Evaluating the empirical False Discovery Rate
estimated_power_KF_bin <- TP / (TP + FN) # Evaluating the empirical Power or TPR

cat("MX-KF (Binary) metrics\n")
cat("Estimated FDR for Target 0.2:", estimated_FDR_KF_bin, "\n")
cat("Estimated Power for Target 0.2:", estimated_power_KF_bin, "\n")

################ Continuous Outcomes (LDA-KF) ##################
df.LDA = as(as.matrix(X),"dgCMatrix")
set.seed(1)
vanilla.LDA <- LDA(df.LDA,k=8,method="VEM") 
theta.LDA <- vanilla.LDA@gamma
beta.LDA <- vanilla.LDA@beta
beta.LDA <- t(apply(beta.LDA,1,function(row) row/sum(row)))
X_tilde.LDA <- zinck::generateKnockoff(X,theta.LDA,beta.LDA,seed=1) ## Generating vanilla LDA knockoff copy


index_est <- zinck.filter(X,X_tilde.LDA,Y1,model="Random Forest",fdr=0.2,offset=0,seed=20)$selected

### Evaluation metrics ###
FN <- sum(index %in% index_est == FALSE) ## False Negatives
FP <- sum(index_est %in% index == FALSE) ## False Positives
TP <- sum(index_est %in% index == TRUE) ## True Positives

estimated_FDR_LDA_cts <- FP / (FP + TP) # Evaluating the empirical False Discovery Rate
estimated_power_LDA_cts <- TP / (TP + FN) # Evaluating the empirical Power or TPR

cat("LDA-KF (Continuous) metrics\n")
cat("Estimated FDR for Target 0.2:", estimated_FDR_LDA_cts, "\n")
cat("Estimated Power for Target 0.2:", estimated_power_LDA_cts, "\n")


############### Binary Outcomes (LDA-KF) ###################

index_est <- zinck.filter(X,X_tilde.LDA,as.factor(Y2),model="Random Forest",fdr=0.2,offset=1,seed=14,rftuning = TRUE,metric="Gini",mtry=67)$selected

### Evaluation metrics ###
FN <- sum(index %in% index_est == FALSE) ## False Negatives
FP <- sum(index_est %in% index == FALSE) ## False Positives
TP <- sum(index_est %in% index == TRUE) ## True Positives

estimated_FDR_LDA_bin <- FP / (FP + TP) # Evaluating the empirical False Discovery Rate
estimated_power_LDA_bin <- TP / (TP + FN) # Evaluating the empirical Power or TPR

cat("LDA-KF (Binary) metrics\n")
cat("Estimated FDR for Target 0.2:", estimated_FDR_LDA_bin, "\n")
cat("Estimated Power for Target 0.2:", estimated_power_LDA_bin, "\n")

```


To summarize the metrics for the three methods, we create the following table. 

```{r table}
# Example collected results for demonstration purposes
results <- data.frame(
  Method = c("Zinck", "MX-KF", "LDA-KF", "Zinck", "MX-KF", "LDA-KF"),
  Outcome = c("Continuous", "Continuous", "Continuous", "Binary", "Binary", "Binary"),
  Power = c(estimated_power_zinck_cts, estimated_power_KF_cts, estimated_power_LDA_cts, estimated_power_zinck_bin, estimated_power_KF_bin, estimated_power_LDA_bin), 
  FDR = c(estimated_FDR_zinck_cts, estimated_FDR_KF_cts, estimated_FDR_LDA_cts, estimated_FDR_zinck_bin, estimated_FDR_KF_bin, estimated_FDR_LDA_bin)   
)
kable(results, format = "html", caption = "Power and Empirical FDR Summary") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))

```

This shows that ``zinck`` has decent power and controlled FDR for both binary and continuous outcome scenarios compared to the other knockoff filters.
